#! /usr/bin/env python
# -*- coding: utf-8 -*-

import os
import copy
import datetime
import gevent
from crawler import Downloader

try:
    from settings import LINK_DIR
except ImportError, e:
    LINK_DIR = 'links'
try:
    from settings import STATISTIC_DIR
except ImportError, e:
    STATISTIC_DIR = 'statistic_data'


fp_link = {}
fp_statistic = {}
for filename in os.listdir(link_dir):
    fp_link[filename] = open(os.path.join(link_dir, filename), 'r')
    fp_statistic[filename] = open(os.path.join(statistic_dir, filename), 'a')


def statistic(links, logger, _type=None):
    begin_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    count = 0
    sum_duration = 0
    d = Downloader()
    for link in links:
        duration = d.get_download_time(link)
        if duration is None:
            continue
        sum_duration += duration 
        count += 1
        gevent.sleep(1)

    avg_duration = sum_duration / count  
    failed_count = len(links) - count
    end_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    logger.write('[ Begin Time: %s, End Time: %s ]\n\n' % (begin_time, end_time))
    logger.write('Links downloaded: %d, links failed: %d\n'\
            % (count, failed_count))
    logger.write('Total time to download all the links: %1.2f\n' % sum_duration)
    logger.write('Average time to download each link: %1.2f\n\n' % avg_duration)
    logger.close()

    if _type:
        print 'Statistic of the type %s links are finished' % _type


def main():
    greenlets = []
    for filename, fp in fp_link.items():
        links = []
        for line in fp:
            links.append(line.strip('\n'))
        fp.close()
        greenlets.append(gevent.spawn(statistic, \
                copy.copy(links), fp_statistic[filename], filename))
    gevent.joinall(greenlets)
    print 'My lord, I have finished my work!'
    print 'You can check out the result in the specified directory'


if __name__ == '__main__':
    main()
